# Code for *Cirruculum Masking to Maximize Cross Modal Interaction in Vision and Language Pretraining* (NAACL '24)

[![Paper](https://img.shields.io/badge/NAACL-2024-blue)](https://aclanthology.org/2024.naacl-long.203/)
[![Email Badge](https://img.shields.io/badge/Gmail-Contact_Me-green?style=flat-square&logo=gmail&logoColor=FFFFFF&labelColor=3A3B3C&color=62F1CD)](mailto:ytou3@gatech.edu)

![Model Architecture](https://github.com/Bred-For-Companionship/CMask/blob/main/dataset/model_architecture.png)

### TODO

- [x] Support parallel training of agent and main model
- [ ] Upload interpretability experiments
- [ ] Support bridging to encoder-decoder VLMs

## ðŸ“š Citation
```
 @inproceedings{tou2024curriculum,
  title={Curriculum Masking in Vision-Language Pretraining to Maximize Cross Modal Interaction},
  author={Tou, Kraig and Sun, Zijun},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={3672--3688},
  year={2024}
}
```





